{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] =  \"0\"\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "## Librerías\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import cv2 as cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import gc\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uso de GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to load images\n",
    "def load_binary_images(file_names):  \n",
    "    image = np.load(file_names).astype(np.float32)\n",
    "    image = np.expand_dims(image, axis=-1)\n",
    "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "    image = tf.image.resize(image, [32,32])   \n",
    "    ## binariazar\n",
    "    image = tf.where(image > 0.5, 1.0, 0.0)  \n",
    "    return image\n",
    "\n",
    "def load_images(file_names):\n",
    "    image = np.load(file_names).astype(np.float32)\n",
    "    #expand_dims\n",
    "    image = np.expand_dims(image, axis=-1)\n",
    "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "    image = tf.image.resize(image, [32,32])/255.0    \n",
    "      \n",
    "    return image\n",
    "\n",
    "def min_max_scaler(ruta,image):\n",
    "    ## load images in the path\n",
    "    images = glob.glob(ruta + '/*.npy')\n",
    "    images = sorted(images)\n",
    "    ## load images\n",
    "    images = [load_images(image) for image in images]\n",
    "    ## min max scaler of thei image using the max and min of all images\n",
    "    images = np.array(images)\n",
    "    max_value = np.max(images)\n",
    "    min_value = np.min(images)\n",
    "    image = tf.math.abs((image - min_value)/(max_value - min_value))\n",
    "    return image   \n",
    "\n",
    "## Function to get contours and features\n",
    "def get_contours_and_features(binary_map):\n",
    "    #https://docs.opencv.org/4.x/d3/d05/tutorial_py_table_of_contents_contours.html\n",
    "    #binary_map = cv2.cvtColor(binary_map, cv2.COLOR_BGR2GRAY)\n",
    "    contours, hierarchy = cv2.findContours(binary_map, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    contours_features = []\n",
    "    for contour in contours:\n",
    "        error = 1e-5\n",
    "        moments = cv2.moments(contour)\n",
    "        cx = moments['m10'] / (moments['m00'] + error)\n",
    "        cy = moments['m01'] / (moments['m00'] + error)\n",
    "        center_of_mass = [cx, cy]\n",
    "        x,y,w,h = cv2.boundingRect(contour)        \n",
    "        rect_area = w*h\n",
    "        features = {\n",
    "            'bounding_box': (x,y,w,h),\n",
    "            'area': cv2.contourArea(contour),\n",
    "            'perimeter': cv2.arcLength(contour, True),       \n",
    "            #'solidity': np.float32(cv2.contourArea(contour))/cv2.convexHull(contour),\n",
    "            'equivalent_diameter': np.sqrt(4*cv2.contourArea(contour)/np.pi),            \n",
    "            'moments': moments,\n",
    "            'center_of_mass': center_of_mass,\n",
    "            'contour': contour\n",
    "        }\n",
    "        contours_features.append(features)\n",
    "        del features\n",
    "    #plt.imshow(contours_map, cmap='gray')\n",
    "    return contours_features\n",
    "\n",
    "# function to get a determined property from a list of contours features (area by default)\n",
    "def get_item(contour_features, key='area'):\n",
    "    areas = []\n",
    "    for contour_feature in contour_features:\n",
    "        area =  contour_feature[key]\n",
    "        areas.append(area)\n",
    "    return areas\n",
    "\n",
    "## function to get geometric_attributes\n",
    "def get_geometric_atributes(binary_images):\n",
    "    descriptors = []\n",
    "    for binary_img in binary_images:\n",
    "        ## Formato\n",
    "        image = binary_img.numpy().astype(np.uint8)       \n",
    "        \n",
    "        ## Capturar contornos\n",
    "        contour_features = get_contours_and_features(image)\n",
    "        \n",
    "        ## Calcular vector de áreas de poro (todos los poros)\n",
    "        areas = get_item(contour_features, key='area')\n",
    "\n",
    "        ## Calcular vector de perímetros de poro (todo los poros)\n",
    "        pmtro = get_item(contour_features, key='perimeter')\n",
    "\n",
    "        ## Calcular el diametro equivalente de los poros\n",
    "        eq_diameter = get_item(contour_features, key='equivalent_diameter')                \n",
    "\n",
    "        descriptor = [np.mean(areas), np.mean(pmtro),np.mean(eq_diameter)]\n",
    "        \n",
    "        descriptors.append(descriptor)\n",
    "        \n",
    "    \n",
    "    return descriptors\n",
    "\n",
    "## function to get the middle image route in the folder\n",
    "def get_middle_image(folder_route):\n",
    "    ## get list of images\n",
    "    images = glob.glob(folder_route + '/*.npy')\n",
    "    ## order images\n",
    "    images = sorted(images)\n",
    "    ## get index of middle image\n",
    "    if len(images) == 0:\n",
    "        indx = -1\n",
    "        middle_image = 'empty'\n",
    "    else:\n",
    "        indx = len(images)//2\n",
    "        middle_image = images[indx]   \n",
    "    \n",
    "    return middle_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## annotations to get nodule_features\n",
    "annotations_cvs_4R = pd.read_csv('/data/Datasets/Nodules_ISBI/meta_created_info_3d_3R.csv')\n",
    "annotations_csv_3R = pd.read_csv('/data/Datasets/Nodules_ISBI/meta_created_info_3d_4R.csv')\n",
    "annotations = pd.concat([annotations_cvs_4R, annotations_csv_3R], ignore_index=True)\n",
    "## drop malignancy = 3\n",
    "annotations = annotations[annotations['malignancy'] != 3]\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ruta dataset\n",
    "rutas_images_npy = glob.glob('/data/Datasets/Nodules_ISBI/images/*/*.npy')\n",
    "\n",
    "## order list by folder\n",
    "rutas_images_npy = sorted(rutas_images_npy)\n",
    "\n",
    "## get list of folders\n",
    "folders = [ruta.split('/')[-2] for ruta in rutas_images_npy]\n",
    "folders = np.unique(folders)\n",
    "\n",
    "## build dataframe\n",
    "rutas_images = []\n",
    "rutas_masks = []\n",
    "areas = []\n",
    "perimetros = []\n",
    "diametros = []\n",
    "calsifications = []\n",
    "spiculations = []\n",
    "lobulations = []\n",
    "sphericities = []\n",
    "textures = []\n",
    "margins = []\n",
    "subletys = []\n",
    "\n",
    "## cancer or not\n",
    "labels = []\n",
    "    \n",
    "for folder in folders:\n",
    "    ruta = '/data/Datasets/Nodules_ISBI/images/' + folder\n",
    "    ruta_masc = '/data/Datasets/Nodules_ISBI/masks/' + folder\n",
    "    \n",
    "    ## load middle image route\n",
    "    image_route = get_middle_image(ruta)\n",
    "    name_image = image_route.split('/')[-1]\n",
    "    mask_route = ruta_masc + '/' + name_image       \n",
    "    \n",
    "    if image_route != 'empty':    \n",
    "        ## get attributes\n",
    "        image = load_images(image_route)\n",
    "        ## min-max scaler\n",
    "        image = min_max_scaler(ruta, image)\n",
    "        ## binary image\n",
    "        binary_image = load_binary_images(mask_route)   \n",
    "        ## get features of the image            \n",
    "        features = annotations[annotations['folder'] == folder]\n",
    "        if features.shape[0] != 0:     \n",
    "            ## append rutas\n",
    "            geometric_attributes = get_geometric_atributes([binary_image])[0]\n",
    "            rutas_images.append(image_route)\n",
    "            rutas_masks.append(mask_route)\n",
    "            \n",
    "            ## append attributes\n",
    "            areas.append(geometric_attributes[0])\n",
    "            perimetros.append(geometric_attributes[1])\n",
    "            diametros.append(geometric_attributes[2])    \n",
    "            \n",
    "            ## evaluar si son nan e iomprimir solo si los  \n",
    "              \n",
    "            malignancy = features['malignancy'].values[0]\n",
    "            calsification = features['calcification'].values[0]\n",
    "            spiculation = features['spiculation'].values[0]\n",
    "            lobulation = features['lobulation'].values[0]\n",
    "            texture = features['texture'].values[0]\n",
    "            label = features['is_cancer'].values[0]\n",
    "            margin = features['margin'].values[0]\n",
    "            sublety = features['subtlety'].values[0]\n",
    "            \n",
    "            ## append featuresprint(features)\n",
    "            calsifications.append(calsification)\n",
    "            spiculations.append(spiculation)\n",
    "            lobulations.append(lobulation)\n",
    "            textures.append(texture)\n",
    "            labels.append(label)\n",
    "            margins.append(margin)\n",
    "            subletys.append(sublety)\n",
    "\n",
    "\n",
    "## build dataframe\n",
    "df = pd.DataFrame()\n",
    "df['ruta'] = rutas_images\n",
    "df['mask'] = rutas_masks\n",
    "df['area'] = areas\n",
    "df['perimetro'] = perimetros\n",
    "df['diametro'] = diametros\n",
    "df['calsification'] = calsifications\n",
    "df['spiculation'] = spiculations\n",
    "df['lobulation'] = lobulations\n",
    "df['texture'] = textures\n",
    "df['margin'] = margins\n",
    "df['sublety'] = subletys\n",
    "df['label'] = labels\n",
    "\n",
    "### eliminar filas con valores nan y decir cuantas se borraron\n",
    "#print('Filas antes de eliminar nan:', df.shape[0])\n",
    "#df = df.dropna()\n",
    "#print('Filas después de eliminar nan:', df.shape[0])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## shuffle data\n",
    "df_train_1, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "## validation split\n",
    "val_pctg = 0.8\n",
    "split_validation_index = int(df_train_1.shape[0]*val_pctg)\n",
    "df_train = df_train_1.iloc[:split_validation_index]\n",
    "df_validation = df_train_1.iloc[split_validation_index:]\n",
    "\n",
    "print('---- Distribución de entrenamiento, validación y test para benignos y malignos ----')\n",
    "print('Malignos: ')\n",
    "print('Positive train shape: ', df_train[df_train['label'] == 'True'].shape[0])\n",
    "print('Positive val shape: ', df_validation[df_validation['label'] == 'True'].shape[0])\n",
    "print('Positive test shape: ', df_test[df_test['label'] == 'True'].shape[0])\n",
    "\n",
    "print('Benignos: ')\n",
    "print('Negative train shape: ', df_train[df_train['label'] == 'False'].shape[0])\n",
    "print('Negative val shape: ', df_validation[df_validation['label'] == 'False'].shape[0])\n",
    "print('Negative test shape: ', df_test[df_test['label'] == 'False'].shape[0])\n",
    "\n",
    "\n",
    "## replace labels\n",
    "df_train.loc[:, 'label'] = df_train['label'].replace({'True': 1, 'False': 0})\n",
    "df_test.loc[:, 'label'] = df_test['label'].replace({'True': 1, 'False': 0})\n",
    "df_validation.loc[:, 'label'] = df_validation['label'].replace({'True': 1, 'False': 0})\n",
    "\n",
    "print('---- Dataset finales ----')\n",
    "print('Train shape: ', df_train.shape[0])\n",
    "print('Test shape: ', df_test.shape[0])\n",
    "print('Validation shape: ', df_validation.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot 5 first images with mas on the df train dataset\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(5):\n",
    "    image = load_images(df_train['ruta'].values[i])    \n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.imshow(image, cmap='gray')   \n",
    "    plt.title('Label: ' + str(df_train['label'].values[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create dataset function \n",
    "features_to_use = ['area','lobulation', 'texture', 'spiculation', 'margin', 'calsification', 'sublety']\n",
    "\n",
    "\n",
    "def create_train_dataset(batch,df):\n",
    "    images_routes = df['ruta'].to_numpy()\n",
    "    mask_routes = df['mask'].to_numpy()\n",
    "    labels = df['label'].to_numpy()\n",
    "    features = df[features_to_use].to_numpy()\n",
    "    \n",
    "    \n",
    "    ## Data augmentation    \n",
    "    def rotate90_image(image):\n",
    "        ## rotate 90 degrees\n",
    "        image = tf.image.rot90(image)\n",
    "        return image\n",
    "    \n",
    "    def rotate180_image(arg):\n",
    "        ## rotate 180 degrees\n",
    "        image = tf.image.rot90(arg, k=2)\n",
    "        return image\n",
    "    \n",
    "    def rotate270_image(arg):\n",
    "        ## rotate 270 degrees\n",
    "        image = tf.image.rot90(arg, k=3)\n",
    "        return image\n",
    "    \n",
    "    images = []\n",
    "    mask = []\n",
    "    new_labels = []\n",
    "    new_features = []\n",
    "    for image_route, mask_route, label, features in zip(images_routes,mask_routes, labels,features):\n",
    "        ## imagenes y mascaras originales\n",
    "        image_original = load_images(image_route)\n",
    "        mask_original = load_binary_images(mask_route)\n",
    "        \n",
    "        ## augmentaciones\n",
    "        # imagen original\n",
    "        #image_left_flip = flip_left_image(image_original)\n",
    "        image_rotate90 = rotate90_image(image_original)\n",
    "        image_rotate180 = rotate180_image(image_original)\n",
    "        image_rotate270 = rotate270_image(image_original)\n",
    "        #image_up_flip = flip_up_image(image_original)\n",
    "        ## mascara original\n",
    "        #mask_left_flip = flip_left_image(mask_original)\n",
    "        mask_rotate90 = rotate90_image(mask_original)\n",
    "        mask_rotate180 = rotate180_image(mask_original)\n",
    "        mask_rotate270 = rotate270_image(mask_original)\n",
    "        #mask_up_flip = flip_up_image(mask_original)\n",
    "        \n",
    "        ## append image augmentation\n",
    "        images.append(image_original)        \n",
    "        images.append(image_rotate90)\n",
    "        images.append(image_rotate180)\n",
    "        images.append(image_rotate270)\n",
    "        \n",
    "        \n",
    "        ## append mask augmentation\n",
    "        mask.append(mask_original)        \n",
    "        mask.append(mask_rotate90)\n",
    "        mask.append(mask_rotate180)\n",
    "        mask.append(mask_rotate270)\n",
    "        \n",
    "        ## append labels        \n",
    "        new_labels.append(label)\n",
    "        new_labels.append(label)\n",
    "        new_labels.append(label)\n",
    "        new_labels.append(label)           \n",
    "        \n",
    "        ## append features  \n",
    "        new_features.append(features)\n",
    "        new_features.append(features)\n",
    "        new_features.append(features)\n",
    "        new_features.append(features)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    ## convert to tensor\n",
    "    images = tf.convert_to_tensor(images, dtype=tf.float32)\n",
    "    masks = tf.convert_to_tensor(mask, dtype=tf.float32)\n",
    "    labels = tf.convert_to_tensor(new_labels, dtype=tf.float32)\n",
    "    features = tf.convert_to_tensor(new_features, dtype=tf.float32)    \n",
    "    \n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, masks, features, labels))\n",
    "    \n",
    "    ## shuffle data\n",
    "    dataset = dataset.shuffle(buffer_size=1000,seed=42)\n",
    "    \n",
    "    ## apply preprocess_image function\n",
    "    dataset = dataset.map(lambda image, mask, features, label: (image, mask, features, label))\n",
    "    \n",
    "    dataset = dataset.batch(batch)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "## create dataset function \n",
    "def create_test_dataset(batch,df):       \n",
    "    images_routes = df['ruta'].to_numpy()\n",
    "    mask_routes = df['mask'].to_numpy()\n",
    "    labels = df['label'].to_numpy()\n",
    "    features = df[features_to_use].to_numpy()\n",
    "    \n",
    "    \n",
    "    images = []\n",
    "    for image_route in images_routes:\n",
    "        image = load_images(image_route)\n",
    "        images.append(image)\n",
    "        \n",
    "    masks = []\n",
    "    for mask_route in mask_routes:\n",
    "        mask = load_binary_images(mask_route)\n",
    "        masks.append(mask)\n",
    "        \n",
    "    ## convert to tensor\n",
    "    images = tf.convert_to_tensor(images, dtype=tf.float32)\n",
    "    masks = tf.convert_to_tensor(mask, dtype=tf.float32)\n",
    "    labels = tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "    features = tf.convert_to_tensor(features, dtype=tf.float32)    \n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, masks, features, labels))\n",
    "    \n",
    "    ## apply preprocess_image function\n",
    "    dataset = dataset.map(lambda image, masks, features, label: (image, masks, features, label))\n",
    "      \n",
    "    dataset.batch(batch)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "## both-clases\n",
    "train_dataset = create_train_dataset(8, df_train)\n",
    "\n",
    "\n",
    "for image, mask, features, label in train_dataset:\n",
    "    print(image.shape)\n",
    "    print(mask.shape)\n",
    "    print(features.shape)\n",
    "    print(label.shape)    \n",
    "    break\n",
    "\n",
    "i = 0 \n",
    "for image, mask, features, label in train_dataset:\n",
    "    i += np.shape(image)[0]   \n",
    "\n",
    "print('Total de imagenes en el dataset de entrenamiento:', i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask, features, label in train_dataset:\n",
    "    ## plot 8 batch images and their mask\n",
    "    plt.figure(figsize=(20,20))\n",
    "    for i in range(8):\n",
    "        plt.subplot(8,2,2*i+1)\n",
    "        plt.imshow(image[i], cmap='gray')       \n",
    "        plt.title('Image')\n",
    "        plt.subplot(8,2,2*i+2)\n",
    "        plt.imshow(mask[i], cmap='gray')\n",
    "        plt.title('Mask')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## decoder\n",
    "nfilters = 16\n",
    "latent_dim = 16\n",
    "nx , ny = 32, 32\n",
    "\n",
    "\n",
    "encoder_input = keras.Input(shape=(nx,ny,1), name='original_img')\n",
    "\n",
    "c1 = layers.Conv2D(nfilters*1, kernel_size=(3,3),\n",
    "               kernel_initializer='he_normal', padding='same')(encoder_input)\n",
    "c1 = layers.BatchNormalization()(c1)\n",
    "c1 = layers.Activation('relu')(c1)\n",
    "p1 = layers.MaxPooling2D((2,2))(c1)\n",
    "p1 = layers.Dropout(0.1)(p1)\n",
    "\n",
    "c2 = layers.Conv2D(nfilters*2, kernel_size=(3,3),\n",
    "               kernel_initializer='he_normal', padding='same')(p1)\n",
    "c2 = layers.BatchNormalization()(c2)\n",
    "c2 = layers.Activation('relu')(c2)\n",
    "p2 = layers.MaxPooling2D((2,2))(c2)\n",
    "\n",
    "c3 = layers.Conv2D(nfilters*4, kernel_size=(3,3),\n",
    "               kernel_initializer='he_normal', padding='same')(p2)\n",
    "c3 = layers.BatchNormalization()(c3)\n",
    "c3 = layers.Activation('relu')(c3)\n",
    "p3 = layers.MaxPooling2D((2,2))(c3)\n",
    "p3 = layers.Dropout(0.1)(p3)\n",
    "\n",
    "c4 = layers.Conv2D(nfilters*8, kernel_size=(3,3),\n",
    "               kernel_initializer='he_normal', padding='same')(p3)\n",
    "c4 = layers.BatchNormalization()(c4)\n",
    "c4 = layers.Activation('relu')(c4)\n",
    "p4 = layers.MaxPooling2D((2,2))(c4)\n",
    "p4 = layers.Dropout(0.1)(p4)\n",
    "\n",
    "c5 = layers.Conv2D(nfilters*16, kernel_size=(3,3),\n",
    "               kernel_initializer='he_normal', padding='same')(p4)\n",
    "\n",
    "# Flatten and Embedding\n",
    "c5_flatten = layers.Flatten()(c5)\n",
    "embbedding = layers.Dense(latent_dim, name='embedding')(c5_flatten)\n",
    "\n",
    "encoder = keras.Model(encoder_input, [embbedding , [c1,c2,c3,c4]], name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## decoder \n",
    "decoder_input = keras.Input(shape=(latent_dim,), name='encoded_img')\n",
    "c1_dec = keras.Input(shape=c1.shape[1:], name='c1_input')\n",
    "c2_dec = keras.Input(shape=c2.shape[1:], name='c2_input')\n",
    "c3_dec = keras.Input(shape=c3.shape[1:], name='c3_input')\n",
    "c4_dec = keras.Input(shape=c4.shape[1:], name='c4_input')\n",
    "\n",
    "## decoder layers from embedding\n",
    "d1_dec = layers.Dense(2*2*256, activation='relu')(decoder_input)\n",
    "d1_dec = layers.Reshape((2, 2, 256))(d1_dec)\n",
    "\n",
    "u1_dec = layers.Conv2DTranspose(nfilters*16, (2,2), strides=(2,2), padding='same')(d1_dec)\n",
    "u1_dec = layers.concatenate([u1_dec, c4_dec])\n",
    "u1_dec = layers.Dropout(0.1)(u1_dec)\n",
    "c6_dec = layers.Conv2D(nfilters*16, kernel_size=(3,3),\n",
    "               kernel_initializer='he_normal', padding='same')(u1_dec)\n",
    "c6_dec = layers.BatchNormalization()(u1_dec)\n",
    "c6_dec = layers.Activation('relu')(u1_dec)\n",
    "\n",
    "u2_dec = layers.Conv2DTranspose(nfilters*8, (2,2), strides=(2,2), padding='same')(c6_dec)\n",
    "u2_dec = layers.concatenate([u2_dec, c3_dec])\n",
    "u2_dec = layers.Dropout(0.1)(u2_dec)\n",
    "c7_dec = layers.Conv2D(nfilters*8, kernel_size=(3,3),\n",
    "               kernel_initializer='he_normal', padding='same')(u2_dec)\n",
    "c7_dec = layers.BatchNormalization()(u2_dec)\n",
    "c7_dec = layers.Activation('relu')(u2_dec)\n",
    "\n",
    "u3_dec = layers.Conv2DTranspose(nfilters*4, (2,2), strides=(2,2), padding='same')(c7_dec)\n",
    "u3_dec = layers.concatenate([u3_dec, c2_dec])\n",
    "u3_dec = layers.Dropout(0.1)(u3_dec)\n",
    "c8_dec = layers.Conv2D(nfilters*4, kernel_size=(3,3),\n",
    "               kernel_initializer='he_normal', padding='same')(u3_dec)\n",
    "c8_dec = layers.BatchNormalization()(u3_dec)\n",
    "c8_dec = layers.Activation('relu')(u3_dec)\n",
    "\n",
    "u4_dec = layers.Conv2DTranspose(nfilters*2, (2,2), strides=(2,2), padding='same')(c8_dec)\n",
    "u4_dec = layers.concatenate([u4_dec, c1_dec])\n",
    "u4_dec = layers.Dropout(0.1)(u4_dec)\n",
    "c9_dec = layers.Conv2D(nfilters*2, kernel_size=(3,3),\n",
    "               kernel_initializer='he_normal', padding='same')(u4_dec)\n",
    "c9_dec = layers.BatchNormalization()(u4_dec)\n",
    "c9_dec = layers.Activation('relu')(u4_dec)\n",
    "\n",
    "\n",
    "segmentation_output = layers.Conv2D(1, (1,1), activation='sigmoid', name='segmentation')(c9_dec)\n",
    "\n",
    "## decoder model\n",
    "decoder = keras.Model([decoder_input, c1_dec, c2_dec, c3_dec, c4_dec], segmentation_output, name='decoder')\n",
    "decoder.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(keras.Model):\n",
    "    def __init__(self, unet_encoder, unet_decoder, **kwargs):\n",
    "        super(Unet, self).__init__()\n",
    "        self.decoder = unet_decoder\n",
    "        self.encoder = unet_encoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.total_loss_tracker, self.reconstruction_loss_tracker]\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        image, mask, features, label = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            embedding, activations = self.encoder(image, training=True)\n",
    "            reconstruction = self.decoder([embedding] + activations, training=True)\n",
    "            reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(mask, reconstruction))\n",
    "            total_loss = reconstruction_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        return {\"total_loss\": self.total_loss_tracker.result(), \"reconstruction_loss\": self.reconstruction_loss_tracker.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 2000\n",
    "batch = 8\n",
    "patience = 15\n",
    "\n",
    "unet = Unet(encoder,decoder)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "unet.compile(optimizer=opt)\n",
    "\n",
    "unet.fit(train_dataset, epochs=epochs,\n",
    "                batch_size=batch,\n",
    "                         callbacks=[tf.keras.callbacks.EarlyStopping(monitor='total_loss', patience=30)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model\n",
    "unet.encoder.save('Unet_Models/encoder_unet.h5')\n",
    "unet.decoder.save('Unet_Models/decoder_unet.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
