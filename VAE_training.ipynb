{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-08 20:19:35.028983: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-08 20:19:35.029022: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-08 20:19:35.032805: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-08 20:19:35.385937: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] =  \"0\"\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "## Librerías\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import cv2 as cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import gc\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uso de GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to load images\n",
    "def load_binary_images(file_names):  \n",
    "    image = np.load(file_names).astype(np.float32)\n",
    "    image = np.expand_dims(image, axis=-1)\n",
    "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "    image = tf.image.resize(image, [32,32])   \n",
    "    ## binariazar\n",
    "    image = tf.where(image > 0.5, 1.0, 0.0)  \n",
    "    return image\n",
    "\n",
    "def load_images(file_names):\n",
    "    image = np.load(file_names).astype(np.float32)\n",
    "    #expand_dims\n",
    "    image = np.expand_dims(image, axis=-1)\n",
    "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "    image = tf.image.resize(image, [32,32])/255.0    \n",
    "      \n",
    "    return image\n",
    "\n",
    "def min_max_scaler(ruta,image):\n",
    "    ## load images in the path\n",
    "    images = glob.glob(ruta + '/*.npy')\n",
    "    images = sorted(images)\n",
    "    ## load images\n",
    "    images = [load_images(image) for image in images]\n",
    "    ## min max scaler of thei image using the max and min of all images\n",
    "    images = np.array(images)\n",
    "    max_value = np.max(images)\n",
    "    min_value = np.min(images)\n",
    "    image = tf.math.abs((image - min_value)/(max_value - min_value))\n",
    "    return image   \n",
    "\n",
    "## Function to get contours and features\n",
    "def get_contours_and_features(binary_map):\n",
    "    #https://docs.opencv.org/4.x/d3/d05/tutorial_py_table_of_contents_contours.html\n",
    "    #binary_map = cv2.cvtColor(binary_map, cv2.COLOR_BGR2GRAY)\n",
    "    contours, hierarchy = cv2.findContours(binary_map, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    contours_features = []\n",
    "    for contour in contours:\n",
    "        error = 1e-5\n",
    "        moments = cv2.moments(contour)\n",
    "        cx = moments['m10'] / (moments['m00'] + error)\n",
    "        cy = moments['m01'] / (moments['m00'] + error)\n",
    "        center_of_mass = [cx, cy]\n",
    "        x,y,w,h = cv2.boundingRect(contour)        \n",
    "        rect_area = w*h\n",
    "        features = {\n",
    "            'bounding_box': (x,y,w,h),\n",
    "            'area': cv2.contourArea(contour),\n",
    "            'perimeter': cv2.arcLength(contour, True),       \n",
    "            #'solidity': np.float32(cv2.contourArea(contour))/cv2.convexHull(contour),\n",
    "            'equivalent_diameter': np.sqrt(4*cv2.contourArea(contour)/np.pi),            \n",
    "            'moments': moments,\n",
    "            'center_of_mass': center_of_mass,\n",
    "            'contour': contour\n",
    "        }\n",
    "        contours_features.append(features)\n",
    "        del features\n",
    "    #plt.imshow(contours_map, cmap='gray')\n",
    "    return contours_features\n",
    "\n",
    "# function to get a determined property from a list of contours features (area by default)\n",
    "def get_item(contour_features, key='area'):\n",
    "    areas = []\n",
    "    for contour_feature in contour_features:\n",
    "        area =  contour_feature[key]\n",
    "        areas.append(area)\n",
    "    return areas\n",
    "\n",
    "## function to get geometric_attributes\n",
    "def get_geometric_atributes(binary_images):\n",
    "    descriptors = []\n",
    "    for binary_img in binary_images:\n",
    "        ## Formato\n",
    "        image = binary_img.numpy().astype(np.uint8)       \n",
    "        \n",
    "        ## Capturar contornos\n",
    "        contour_features = get_contours_and_features(image)\n",
    "        \n",
    "        ## Calcular vector de áreas de poro (todos los poros)\n",
    "        areas = get_item(contour_features, key='area')\n",
    "\n",
    "        ## Calcular vector de perímetros de poro (todo los poros)\n",
    "        pmtro = get_item(contour_features, key='perimeter')\n",
    "\n",
    "        ## Calcular el diametro equivalente de los poros\n",
    "        eq_diameter = get_item(contour_features, key='equivalent_diameter')                \n",
    "\n",
    "        descriptor = [np.mean(areas), np.mean(pmtro),np.mean(eq_diameter)]\n",
    "        \n",
    "        descriptors.append(descriptor)\n",
    "        \n",
    "    \n",
    "    return descriptors\n",
    "\n",
    "## function to get the middle image route in the folder\n",
    "def get_middle_image(folder_route):\n",
    "    ## get list of images\n",
    "    images = glob.glob(folder_route + '/*.npy')\n",
    "    ## order images\n",
    "    images = sorted(images)\n",
    "    ## get index of middle image\n",
    "    if len(images) == 0:\n",
    "        indx = -1\n",
    "        middle_image = 'empty'\n",
    "    else:\n",
    "        indx = int(np.floor(len(images)/2))\n",
    "        middle_image = images[indx]   \n",
    "    \n",
    "    return middle_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## annotations to get nodule_features\n",
    "annotations_cvs_4R = pd.read_csv('/data/Datasets/Nodules_ISBI/meta_created_info_3d_4R.csv')\n",
    "annotations_csv_3R = pd.read_csv('/data/Datasets/Nodules_ISBI/meta_created_info_3d_3R.csv')\n",
    "annotations = pd.concat([annotations_cvs_4R, annotations_csv_3R])\n",
    "## drop malignancy = 3\n",
    "annotations = annotations[annotations['malignancy'] != 3]\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ruta dataset\n",
    "rutas_images_npy = glob.glob('/data/Datasets/Nodules_ISBI/images/*/*.npy')\n",
    "\n",
    "## order list by folder\n",
    "rutas_images_npy = sorted(rutas_images_npy)\n",
    "\n",
    "## get list of folders\n",
    "folders = [ruta.split('/')[-2] for ruta in rutas_images_npy]\n",
    "folders = np.unique(folders)\n",
    "\n",
    "## build dataframe\n",
    "rutas_images = []\n",
    "rutas_masks = []\n",
    "areas = []\n",
    "perimetros = []\n",
    "diametros = []\n",
    "calsifications = []\n",
    "spiculations = []\n",
    "lobulations = []\n",
    "sphericities = []\n",
    "textures = []\n",
    "margins = []\n",
    "\n",
    "## cancer or not\n",
    "labels = []\n",
    "    \n",
    "for folder in folders:\n",
    "    ruta = '/data/Datasets/Nodules_ISBI/images/' + folder\n",
    "    ruta_masc = '/data/Datasets/Nodules_ISBI/masks/' + folder\n",
    "    \n",
    "    ## load middle image route\n",
    "    image_route = get_middle_image(ruta)\n",
    "    name_image = image_route.split('/')[-1]\n",
    "    mask_route = ruta_masc + '/' + name_image       \n",
    "    \n",
    "    if image_route != 'empty':    \n",
    "        ## get attributes\n",
    "        image = load_images(image_route)\n",
    "        ## min-max scaler\n",
    "        image = min_max_scaler(ruta, image)\n",
    "        ## binary image\n",
    "        binary_image = load_binary_images(mask_route)   \n",
    "        ## get features of the image            \n",
    "        features = annotations[annotations['folder'] == folder]\n",
    "        if features.shape[0] != 0:     \n",
    "            ## append rutas\n",
    "            geometric_attributes = get_geometric_atributes([binary_image])[0]\n",
    "            rutas_images.append(image_route)\n",
    "            rutas_masks.append(mask_route)\n",
    "            \n",
    "            ## append attributes\n",
    "            areas.append(geometric_attributes[0])\n",
    "            perimetros.append(geometric_attributes[1])\n",
    "            diametros.append(geometric_attributes[2])     \n",
    "              \n",
    "            malignancy = features['malignancy'].values[0]\n",
    "            calsification = features['calcification'].values[0]\n",
    "            spiculation = features['spiculation'].values[0]\n",
    "            lobulation = features['lobulation'].values[0]\n",
    "            texture = features['texture'].values[0]\n",
    "            label = features['is_cancer'].values[0]\n",
    "            margin = features['margin'].values[0]\n",
    "            \n",
    "            ## append featuresprint(features)\n",
    "            calsifications.append(calsification)\n",
    "            spiculations.append(spiculation)\n",
    "            lobulations.append(lobulation)\n",
    "            textures.append(texture)\n",
    "            labels.append(label)\n",
    "            margins.append(margin)\n",
    "\n",
    "\n",
    "## build dataframe\n",
    "df = pd.DataFrame()\n",
    "df['ruta'] = rutas_images\n",
    "df['mask'] = rutas_masks\n",
    "df['area'] = areas\n",
    "df['perimetro'] = perimetros\n",
    "df['diametro'] = diametros\n",
    "df['calsification'] = calsifications\n",
    "df['spiculation'] = spiculations\n",
    "df['lobulation'] = lobulations\n",
    "df['texture'] = textures\n",
    "df['margin'] = margins\n",
    "df['label'] = labels\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot a random image with mask\n",
    "indx = np.random.randint(0, df.shape[0])\n",
    "image = load_images(df['ruta'].values[indx])\n",
    "mask = load_binary_images(df['mask'].values[indx])\n",
    "\n",
    "print(np.shape(image), np.shape(mask),type(image), type(mask))\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('Image')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.title('Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = df[df['label'] == 'True']\n",
    "df_negative = df[df['label'] == 'False']\n",
    "\n",
    "print('Positive shape: ', df_positive.shape)\n",
    "print('Negative shape: ', df_negative.shape)\n",
    "\n",
    "## seed \n",
    "np.random.seed(0)\n",
    "\n",
    "## shuffle data\n",
    "df_positive = df_positive.sample(frac=1)\n",
    "df_negative = df_negative.sample(frac=1)\n",
    "\n",
    "## sample 120 positive and 120 negative\n",
    "pctg = 0.8\n",
    "n_train_samples_positive = int(df_positive.shape[0]*pctg)\n",
    "n_train_samples_negative = int(df_negative.shape[0]*pctg)\n",
    "\n",
    "df_positive_train = df_positive.iloc[:n_train_samples_positive]\n",
    "df_positive_test = df_positive.iloc[n_train_samples_positive:]\n",
    "\n",
    "df_negative_train = df_negative.iloc[:n_train_samples_negative]\n",
    "df_negative_test = df_negative.iloc[n_train_samples_negative:]\n",
    "\n",
    "print('Positive train shape: ', df_positive_train.shape)\n",
    "print('Positive test shape: ', df_positive_test.shape)\n",
    "print('Negative train shape: ', df_negative_train.shape)\n",
    "print('Negative test shape: ', df_negative_test.shape)\n",
    "\n",
    "## concat dataframes\n",
    "df_train = pd.concat([df_positive_train, df_negative_train])\n",
    "df_test = pd.concat([df_positive_test, df_negative_test])\n",
    "\n",
    "## re-shuffle data\n",
    "df_train = df_train.sample(frac=1)\n",
    "df_test = df_test.sample(frac=1)\n",
    "\n",
    "## replace labels\n",
    "df_train['label'] = df_train['label'].replace({'True': 1, 'False': 0})\n",
    "df_test['label'] = df_test['label'].replace({'True': 1, 'False': 0})\n",
    "\n",
    "print('Train shape: ', df_train.shape)\n",
    "print('Test shape: ', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create dataset function \n",
    "def create_train_dataset(batch,df):\n",
    "    images_routes = df['ruta'].to_numpy()\n",
    "    labels = df['label'].to_numpy()\n",
    "    features = df[['area', 'spiculation', 'lobulation', 'margin','texture']].to_numpy()\n",
    "    \n",
    "    \n",
    "    ## Data augmentation\n",
    "    def flip_left_image(image):\n",
    "        ## flip left-right\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        return image\n",
    "    \n",
    "    def rotate90_image(image):\n",
    "        ## rotate 90 degrees\n",
    "        image = tf.image.rot90(image)\n",
    "        return image\n",
    "    \n",
    "    def rotate180_image(arg):\n",
    "        ## rotate 180 degrees\n",
    "        image = tf.image.rot90(arg, k=2)\n",
    "        return image\n",
    "    \n",
    "    def flip_right_image(image):\n",
    "        ## flip up-down\n",
    "        image = tf.image.random_flip_up_down(image)\n",
    "        return image\n",
    "    \n",
    "    def flip_up_image(image):\n",
    "        ## flip up-down\n",
    "        image = tf.image.random_flip_up_down(image)\n",
    "        return image\n",
    "    \n",
    "    def flip_up_image(image):\n",
    "        ## flip up-down\n",
    "        image = tf.image.random_flip_up_down(image)\n",
    "        return image\n",
    "        \n",
    "    \n",
    "    images = []\n",
    "    new_labels = []\n",
    "    new_features = []\n",
    "    for image_route, label, features in zip(images_routes, labels,features):\n",
    "        image_original = load_images(image_route)\n",
    "        image_left_flip = flip_left_image(image_original)\n",
    "        image_rotate90 = rotate90_image(image_original)\n",
    "        image_rotate180 = rotate180_image(image_original)\n",
    "        image_up_flip = flip_up_image(image_original)\n",
    "        images.append(image_original)\n",
    "        images.append(image_left_flip)\n",
    "        images.append(image_rotate90)\n",
    "        images.append(image_rotate180)\n",
    "        images.append(image_up_flip)\n",
    "        new_labels.append(label)\n",
    "        new_labels.append(label)\n",
    "        new_labels.append(label)\n",
    "        new_labels.append(label)\n",
    "        new_labels.append(label)       \n",
    "        new_features.append(features)\n",
    "        new_features.append(features)\n",
    "        new_features.append(features)\n",
    "        new_features.append(features)\n",
    "        new_features.append(features)\n",
    "        \n",
    "        \n",
    "        \n",
    "    ## convert to tensor\n",
    "    images = tf.convert_to_tensor(images, dtype=tf.float32)\n",
    "    labels = tf.convert_to_tensor(new_labels, dtype=tf.float32)\n",
    "    features = tf.convert_to_tensor(new_features, dtype=tf.float32)    \n",
    "    \n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, features, labels))\n",
    "    \n",
    "    ## apply preprocess_image function\n",
    "    dataset = dataset.map(lambda image, features, label: (image, features, label))\n",
    "    \n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    \n",
    "    dataset = dataset.batch(batch)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "## create dataset function \n",
    "def create_test_dataset(batch,df):    \n",
    "    ## randomize data\n",
    "    df = df.sample(frac=1)\n",
    "    \n",
    "    images_routes = df['ruta'].to_numpy()\n",
    "    labels = df['label'].to_numpy()\n",
    "    features = df[['area', 'spiculation', 'lobulation', 'margin','texture']].to_numpy()\n",
    "    \n",
    "    \n",
    "    images = []\n",
    "    for image_route in images_routes:\n",
    "        image = load_images(image_route)\n",
    "        images.append(image)\n",
    "        \n",
    "    ## convert to tensor\n",
    "    images = tf.convert_to_tensor(images, dtype=tf.float32)\n",
    "    labels = tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "    features = tf.convert_to_tensor(features, dtype=tf.float32)    \n",
    "    \n",
    "      \n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, features, labels))\n",
    "    \n",
    "    ## apply preprocess_image function\n",
    "    dataset = dataset.map(lambda image, features, label: (image, features, label))\n",
    "      \n",
    "      \n",
    "    dataset.batch(batch)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "## both-clases\n",
    "train_dataset = create_train_dataset(8, df_train)\n",
    "\n",
    "# train dataset with just no-cancer class\n",
    "#train_dataset = create_train_dataset(16, df_train.drop(df_train[df_train['label'] == 1].index))\n",
    "\n",
    "for image, features, label in train_dataset:\n",
    "    print(image.shape)\n",
    "    print(features.shape)\n",
    "    print(label.shape)\n",
    "    break\n",
    "\n",
    "i = 0 \n",
    "for image, features, label in train_dataset:\n",
    "    i += np.shape(image)[0]\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, features, label in train_dataset:\n",
    "    ## plot 8 batch images\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(8):\n",
    "        plt.subplot(4,2,i+1)\n",
    "        plt.imshow(image[i], cmap='gray')\n",
    "        plt.title('Label: ' + str(label[i].numpy()))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparámetros\n",
    "epochs = 2000\n",
    "learning_rate = 0.0001\n",
    "batch = 8\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###_____________________________ENCODER________________________##\n",
    "latent_dim = 8\n",
    "\n",
    "nx, ny = 32, 32\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(nx, ny, 1))\n",
    "\n",
    "x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same',name='layer_E1')(encoder_inputs)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same',name='layer_E2')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(16, (2, 2), activation='relu', padding='same',name='layer_E6')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(8, (2, 2), activation='relu', padding='same',name='layer_E7')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(4, (2, 2), activation='relu', padding='same',name='layer_E8')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(inputs=encoder_inputs, outputs=[z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ------------------ decoder -------------------------\n",
    "## Entrada Z\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "##dimensiones\n",
    "ndim = 4\n",
    "nfilts = 32\n",
    "\n",
    "## anti-flatten de la última capa convolucional\n",
    "x = layers.Dense(ndim * ndim * nfilts, activation=\"relu\")(latent_inputs)\n",
    "\n",
    "## Reshape para reconstruir la última convolucional\n",
    "x = layers.Reshape((ndim,ndim, nfilts))(x)\n",
    "\n",
    "## Capas convolucionales\n",
    "x = tf.keras.layers.Conv2D(4, (2, 2), activation='relu', padding='same',name='layer_D1')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(8, (2, 2), activation='relu', padding='same',name='layer_D2')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(16, (2, 2), activation='relu', padding='same',name='layer_D3')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(32, (2, 2), activation='relu', padding='same',name='layer_D4')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(32, (2, 2), activation='relu', padding='same',name='layer_D5')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "decoder_outputs = tf.keras.layers.Conv2D(1, (2, 2), activation='sigmoid', padding='same',name='layer_D6')(x)\n",
    "\n",
    "## Construcción del decoder\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")        \n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            \n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "        \n",
    "            z_mean, z_log_var, z = self.encoder(data[0])\n",
    "            reconstruction = self.decoder(z)\n",
    "            #reconstruction /= tf.reduce_max(reconstruction)\n",
    "            \n",
    "            \n",
    "            reconstruction_loss = tf.math.abs(tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                   keras.losses.binary_crossentropy(data[0], reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            ))\n",
    "            \n",
    "            \n",
    "            '''\n",
    "            reconstruction_loss =tf.reduce_mean(\n",
    "                tf.reduce_sum( tf.keras.losses.MeanSquaredError()(data, reconstruction)\n",
    "                             )\n",
    "            )\n",
    "            '''\n",
    "            \n",
    "            \n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            \n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))       \n",
    "               \n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "            \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)        \n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)       \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),            \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "opt = tf.optimizers.Adam(learning_rate = learning_rate, )\n",
    "#nll = lambda x , rv_x: -rv_x.log_prob(x)\n",
    "vae.compile(optimizer=opt)\n",
    "\n",
    "\n",
    "vae.fit(train_dataset, epochs=epochs, \n",
    "                batch_size=batch,\n",
    "                         callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=30)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Guardar modelohttps://www.tensorflow.org/guide/saved_model?hl=es-419\n",
    "vae.encoder.save('VAE_Models/GVAE_8_encoder.h5')\n",
    "vae.decoder.save('VAE_Models/GVAE_8_decoder.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GVAE + REGRESSOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###_____________________________ENCODER________________________##\n",
    "latent_dim = 8\n",
    "\n",
    "nx, ny = 32, 32\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(nx, ny, 1))\n",
    "\n",
    "x = tf.keras.layers.Conv2D(32, (3, 3), activation='tanh', padding='same',name='layer_E1')(encoder_inputs)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(8, (3, 3), activation='tanh', padding='same',name='layer_E2')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(4, (2, 2), activation='tanh', padding='same',name='layer_E6')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(inputs=encoder_inputs, outputs=[z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ------------------ decoder -------------------------\n",
    "## Entrada Z\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "##dimensiones\n",
    "ndim = 4\n",
    "nfilts = 64\n",
    "\n",
    "## anti-flatten de la última capa convolucional\n",
    "x = layers.Dense(ndim * ndim * nfilts, activation=\"relu\")(latent_inputs)\n",
    "\n",
    "## Reshape para reconstruir la última convolucional\n",
    "x = layers.Reshape((ndim,ndim, nfilts))(x)\n",
    "\n",
    "## Capas convolucionales\n",
    "x = tf.keras.layers.Conv2D(16, (2, 2), activation='relu', padding='same',name='layer_D1')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(8, (2, 2), activation='relu', padding='same',name='layer_D2')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(4, (2, 2), activation='relu', padding='same',name='layer_D4')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "decoder_outputs = tf.keras.layers.Conv2D(1, (2, 2), activation='sigmoid', padding='same',name='layer_D7')(x)\n",
    "\n",
    "## Construcción del decoder\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## --------------- REGRESOR ---------------------\n",
    "### Estimador de valores geométricos\n",
    "\n",
    "## Input layer\n",
    "regressor_inputs = keras.Input(shape=(32, 32, 1))\n",
    "\n",
    "# Example of your model layers\n",
    "x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='layer_R1')(regressor_inputs)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same', name='layer_R2')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same', name='layer_R3')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same', name='layer_R4')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(4, (3, 3), activation='relu', padding='same', name='layer_R5')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same', name='layer_R6')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(8, activation='relu')(x)\n",
    "\n",
    "# Define the outputs\n",
    "area_output = tf.keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "spiculation_output = tf.keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "lobulation_output = tf.keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "margin_output = tf.keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "texture_output = tf.keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "# Ensure you use the correct input tensor\n",
    "regressor = keras.Model(regressor_inputs, [area_output, spiculation_output, lobulation_output, margin_output, texture_output], name=\"regressor\")\n",
    "\n",
    "# Print model summary\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_regressor(keras.Model):\n",
    "    def __init__(self, encoder, decoder, regressor, **kwargs):\n",
    "        super(VAE_regressor, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.regressor = regressor\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")        \n",
    "        self.estimation_loss_tracker = keras.metrics.Mean(name=\"estimation_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            self.estimation_loss_tracker,            \n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            ## Valores estimados por el encoder\n",
    "            z_mean, z_log_var, z = self.encoder(data[0])\n",
    "            \n",
    "                    \n",
    "            ## Valores geométricos asociados a los datos\n",
    "            geometrics_features = data[1]\n",
    "            \n",
    "\n",
    "            ## Reconstrucción del embebido del encoder\n",
    "            reconstruction = self.decoder(z)            \n",
    "\n",
    "            ## Reducción de la reconstrucción\n",
    "            reconstruction /= tf.reduce_mean(reconstruction)\n",
    "\n",
    "            ## Valores estimados apartir del regresor            \n",
    "            estimations = self.regressor(reconstruction)            \n",
    "            \n",
    "            \n",
    "            ## Error de reconstrucción\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data[0], reconstruction  + tf.keras.backend.epsilon()), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "            '''\n",
    "            reconstruction_loss =tf.reduce_mean(\n",
    "                tf.reduce_sum( tf.keras.losses.MeanSquaredError()(data, reconstruction)\n",
    "                             )\n",
    "            )\n",
    "            '''\n",
    "            \n",
    "            ## Error de estimación de valores geométricos\n",
    "                        \n",
    "            estimation_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.mean_squared_error(geometrics_features, estimations), axis=(1)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            \n",
    "            ## Error de divergencia KL\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))   \n",
    "\n",
    "            ## Error total          \n",
    "            total_loss = reconstruction_loss + kl_loss + estimation_loss\n",
    "        \n",
    "        ## Actualización de los gradientes\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        grads = [tf.clip_by_value(grad, -1.0, 1.0) for grad in grads]\n",
    "\n",
    "        ### Actualización de los pesos\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)   \n",
    "        self.estimation_loss_tracker.update_state(estimation_loss)    \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(), \n",
    "            \"ArithmeticError\": self.estimation_loss_tracker.result(),        \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE_regressor(encoder, decoder,regressor)\n",
    "opt = tf.optimizers.Adam(learning_rate = learning_rate)\n",
    "#nll = lambda x , rv_x: -rv_x.log_prob(x)\n",
    "vae.compile(optimizer=opt)\n",
    "\n",
    "\n",
    "vae.fit(train_dataset, epochs=epochs, \n",
    "                batch_size=batch,\n",
    "                         callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Guardar modelohttps://www.tensorflow.org/guide/saved_model?hl=es-419\n",
    "vae.encoder.save('DistVAE_Models/GVAE_encoder_8_only_regressor_1.h5')\n",
    "vae.decoder.save('DistVAE_Models/GVAE_decoder_8_only_regressor_1.h5')\n",
    "vae.regressor.save('DistVAE_Models/GVAE_regressor_8_only_regressor_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\beta$-VAES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###_____________________________ENCODER________________________##\n",
    "latent_dim = 8\n",
    "\n",
    "nx, ny = 32, 32\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(nx, ny, 1))\n",
    "\n",
    "x = tf.keras.layers.Conv2D(32, (3, 3), activation='tanh', padding='same',name='layer_E1')(encoder_inputs)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(8, (3, 3), activation='tanh', padding='same',name='layer_E2')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(4, (2, 2), activation='tanh', padding='same',name='layer_E6')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(inputs=encoder_inputs, outputs=[z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ------------------ decoder -------------------------\n",
    "## Entrada Z\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "##dimensiones\n",
    "ndim = 4\n",
    "nfilts = 84\n",
    "\n",
    "## anti-flatten de la última capa convolucional\n",
    "x = layers.Dense(ndim * ndim * nfilts, activation=\"relu\")(latent_inputs)\n",
    "\n",
    "## Reshape para reconstruir la última convolucional\n",
    "x = layers.Reshape((ndim,ndim, nfilts))(x)\n",
    "\n",
    "## Capas convolucionales\n",
    "x = tf.keras.layers.Conv2D(16, (2, 2), activation='relu', padding='same',name='layer_D1')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(8, (2, 2), activation='relu', padding='same',name='layer_D2')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(4, (2, 2), activation='relu', padding='same',name='layer_D4')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "decoder_outputs = tf.keras.layers.Conv2D(1, (2, 2), activation='sigmoid', padding='same',name='layer_D7')(x)\n",
    "\n",
    "## Construcción del decoder\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, betha,**kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.betha = betha\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")        \n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            \n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "        \n",
    "            z_mean, z_log_var, z = self.encoder(data[0])\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction /= tf.reduce_max(reconstruction)\n",
    "            \n",
    "            \n",
    "            reconstruction_loss = tf.abs(tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                   keras.losses.binary_crossentropy(data[0], reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            ))\n",
    "            \n",
    "            \n",
    "            '''\n",
    "            reconstruction_loss =tf.reduce_mean(\n",
    "                tf.reduce_sum( tf.keras.losses.MeanSquaredError()(data, reconstruction)\n",
    "                             )\n",
    "            )\n",
    "            '''\n",
    "            \n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            \n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))         \n",
    "               \n",
    "            total_loss = reconstruction_loss + self.betha*kl_loss\n",
    "            \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)        \n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)       \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),            \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bethas = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "for betha in bethas:\n",
    "    vae = VAE(encoder, decoder, betha)\n",
    "    opt = tf.optimizers.Adam(learning_rate = learning_rate)\n",
    "    #nll = lambda x , rv_x: -rv_x.log_prob(x)\n",
    "    vae.compile(optimizer=opt)\n",
    "\n",
    "\n",
    "    vae.fit(train_dataset, epochs=epochs, \n",
    "                    batch_size=batch,\n",
    "                            callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=30)])\n",
    "    \n",
    "    \n",
    "    ## save models\n",
    "    vae.encoder.save('BetaVAE_Models/betha_'+str(betha)+'/GVAE_8_encoder_betha_{}_.h5'.format(betha))\n",
    "    vae.decoder.save('BetaVAE_Models/betha_'+str(betha)+'/GVAE_8_decoder_betha_{}_.h5'.format(betha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GVAE-Weigthed descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")        \n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            \n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "        \n",
    "            z_mean, z_log_var, z = self.encoder(data[0])\n",
    "            reconstruction = self.decoder(z)\n",
    "            #reconstruction /= tf.reduce_max(reconstruction)\n",
    "            \n",
    "            z = tf.matmul(z, features, transpose_a=True)\n",
    "            \n",
    "            reconstruction_loss = tf.math.abs(tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                   keras.losses.binary_crossentropy(data[0], reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            ))\n",
    "            \n",
    "            \n",
    "            '''\n",
    "            reconstruction_loss =tf.reduce_mean(\n",
    "                tf.reduce_sum( tf.keras.losses.MeanSquaredError()(data, reconstruction)\n",
    "                             )\n",
    "            )\n",
    "            '''\n",
    "            \n",
    "            \n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            \n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))         \n",
    "               \n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "            \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)        \n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)       \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),            \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ------------------ decoder -------------------------\n",
    "## Entrada Z\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "##dimensiones\n",
    "ndim = 4\n",
    "nfilts = 84\n",
    "\n",
    "## anti-flatten de la última capa convolucional\n",
    "x = layers.Dense(ndim * ndim * nfilts, activation=\"relu\")(latent_inputs)\n",
    "\n",
    "## Reshape para reconstruir la última convolucional\n",
    "x = layers.Reshape((ndim,ndim, nfilts))(x)\n",
    "\n",
    "## Capas convolucionales\n",
    "x = tf.keras.layers.Conv2D(16, (2, 2), activation='relu', padding='same',name='layer_D1')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(8, (2, 2), activation='relu', padding='same',name='layer_D2')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(4, (2, 2), activation='relu', padding='same',name='layer_D4')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "decoder_outputs = tf.keras.layers.Conv2D(1, (2, 2), activation='sigmoid', padding='same',name='layer_D7')(x)\n",
    "\n",
    "## Construcción del decoder\n",
    "decoder_WeightEmbs = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder_WeightEmbs.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, decoder_WeightEmbs)\n",
    "opt = tf.optimizers.Adam(learning_rate = learning_rate)\n",
    "#nll = lambda x , rv_x: -rv_x.log_prob(x)\n",
    "vae.compile(optimizer=opt)\n",
    "\n",
    "\n",
    "vae.fit(train_dataset, epochs=epochs, \n",
    "                batch_size=batch,\n",
    "                         callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=30)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Guardar modelohttps://www.tensorflow.org/guide/saved_model?hl=es-419\n",
    "vae.encoder.save('VAE_Models/Weight_GVAE_16_encoder.h5')\n",
    "vae.decoder.save('VAE_Models/Weight_GVAE_16_decoder.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
