{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 05:26:46.637394: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-20 05:26:46.637432: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-20 05:26:46.641999: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-20 05:26:46.917828: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] =  \"0\"\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "## Librerías\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import cv2 as cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import gc\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 05:26:52.170993: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-20 05:26:52.269481: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-20 05:26:52.269814: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "## Uso de GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to load images\n",
    "def load_binary_images(file_names):  \n",
    "    image = np.load(file_names).astype(np.float32)\n",
    "    image = np.expand_dims(image, axis=-1)\n",
    "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "    image = tf.image.resize(image, [32,32])   \n",
    "    ## binariazar\n",
    "    image = tf.where(image > 0.5, 1.0, 0.0)  \n",
    "    return image\n",
    "\n",
    "def load_images(file_names):\n",
    "    image = np.load(file_names).astype(np.float32)\n",
    "    #expand_dims\n",
    "    image = np.expand_dims(image, axis=-1)\n",
    "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "    image = tf.image.resize(image, [32,32])/255.0    \n",
    "      \n",
    "    return image\n",
    "\n",
    "def min_max_scaler(ruta,image):\n",
    "    ## load images in the path\n",
    "    images = glob.glob(ruta + '/*.npy')\n",
    "    images = sorted(images)\n",
    "    ## load images\n",
    "    images = [load_images(image) for image in images]\n",
    "    ## min max scaler of thei image using the max and min of all images\n",
    "    images = np.array(images)\n",
    "    max_value = np.max(images)\n",
    "    min_value = np.min(images)\n",
    "    image = tf.math.abs((image - min_value)/(max_value - min_value))\n",
    "    return image   \n",
    "\n",
    "## Function to get contours and features\n",
    "def get_contours_and_features(binary_map):\n",
    "    #https://docs.opencv.org/4.x/d3/d05/tutorial_py_table_of_contents_contours.html\n",
    "    #binary_map = cv2.cvtColor(binary_map, cv2.COLOR_BGR2GRAY)\n",
    "    contours, hierarchy = cv2.findContours(binary_map, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    contours_features = []\n",
    "    for contour in contours:\n",
    "        error = 1e-5\n",
    "        moments = cv2.moments(contour)\n",
    "        cx = moments['m10'] / (moments['m00'] + error)\n",
    "        cy = moments['m01'] / (moments['m00'] + error)\n",
    "        center_of_mass = [cx, cy]\n",
    "        x,y,w,h = cv2.boundingRect(contour)        \n",
    "        rect_area = w*h\n",
    "        features = {\n",
    "            'bounding_box': (x,y,w,h),\n",
    "            'area': cv2.contourArea(contour),\n",
    "            'perimeter': cv2.arcLength(contour, True),       \n",
    "            #'solidity': np.float32(cv2.contourArea(contour))/cv2.convexHull(contour),\n",
    "            'equivalent_diameter': np.sqrt(4*cv2.contourArea(contour)/np.pi),            \n",
    "            'moments': moments,\n",
    "            'center_of_mass': center_of_mass,\n",
    "            'contour': contour\n",
    "        }\n",
    "        contours_features.append(features)\n",
    "        del features\n",
    "    #plt.imshow(contours_map, cmap='gray')\n",
    "    return contours_features\n",
    "\n",
    "# function to get a determined property from a list of contours features (area by default)\n",
    "def get_item(contour_features, key='area'):\n",
    "    areas = []\n",
    "    for contour_feature in contour_features:\n",
    "        area =  contour_feature[key]\n",
    "        areas.append(area)\n",
    "    return areas\n",
    "\n",
    "## function to get geometric_attributes\n",
    "def get_geometric_atributes(binary_images):\n",
    "    descriptors = []\n",
    "    for binary_img in binary_images:\n",
    "        ## Formato\n",
    "        image = binary_img.numpy().astype(np.uint8)       \n",
    "        \n",
    "        ## Capturar contornos\n",
    "        contour_features = get_contours_and_features(image)\n",
    "        \n",
    "        ## Calcular vector de áreas de poro (todos los poros)\n",
    "        areas = get_item(contour_features, key='area')\n",
    "\n",
    "        ## Calcular vector de perímetros de poro (todo los poros)\n",
    "        pmtro = get_item(contour_features, key='perimeter')\n",
    "\n",
    "        ## Calcular el diametro equivalente de los poros\n",
    "        eq_diameter = get_item(contour_features, key='equivalent_diameter')                \n",
    "\n",
    "        descriptor = [np.mean(areas), np.mean(pmtro),np.mean(eq_diameter)]\n",
    "        \n",
    "        descriptors.append(descriptor)\n",
    "        \n",
    "    \n",
    "    return descriptors\n",
    "\n",
    "## function to get the middle image route in the folder\n",
    "def get_middle_image(folder_route):\n",
    "    ## get list of images\n",
    "    images = glob.glob(folder_route + '/*.npy')\n",
    "    ## order images\n",
    "    images = sorted(images)\n",
    "    ## get index of middle image\n",
    "    if len(images) == 0:\n",
    "        indx = -1\n",
    "        middle_image = 'empty'\n",
    "    else:\n",
    "        indx = len(images)//2\n",
    "        middle_image = images[indx]   \n",
    "    \n",
    "    return middle_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## annotations to get nodule_features\n",
    "annotations_cvs_4R = pd.read_csv('/data/Datasets/Nodules_ISBI/meta_created_info_3d_3R.csv')\n",
    "annotations_csv_3R = pd.read_csv('/data/Datasets/Nodules_ISBI/meta_created_info_3d_4R.csv')\n",
    "annotations = pd.concat([annotations_cvs_4R, annotations_csv_3R], ignore_index=True)\n",
    "## drop malignancy = 3\n",
    "annotations = annotations[annotations['malignancy'] != 3]\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ruta dataset\n",
    "rutas_images_npy = glob.glob('/data/Datasets/Nodules_ISBI/images/*/*.npy')\n",
    "\n",
    "## order list by folder\n",
    "rutas_images_npy = sorted(rutas_images_npy)\n",
    "\n",
    "## get list of folders\n",
    "folders = [ruta.split('/')[-2] for ruta in rutas_images_npy]\n",
    "folders = np.unique(folders)\n",
    "\n",
    "## build dataframe\n",
    "rutas_images = []\n",
    "rutas_masks = []\n",
    "areas = []\n",
    "perimetros = []\n",
    "diametros = []\n",
    "calsifications = []\n",
    "spiculations = []\n",
    "lobulations = []\n",
    "sphericities = []\n",
    "textures = []\n",
    "margins = []\n",
    "subletys = []\n",
    "\n",
    "## cancer or not\n",
    "labels = []\n",
    "    \n",
    "for folder in folders:\n",
    "    ruta = '/data/Datasets/Nodules_ISBI/images/' + folder\n",
    "    ruta_masc = '/data/Datasets/Nodules_ISBI/masks/' + folder\n",
    "    \n",
    "    ## load middle image route\n",
    "    image_route = get_middle_image(ruta)\n",
    "    name_image = image_route.split('/')[-1]\n",
    "    mask_route = ruta_masc + '/' + name_image       \n",
    "    \n",
    "    if image_route != 'empty':    \n",
    "        ## get attributes\n",
    "        image = load_images(image_route)\n",
    "        ## min-max scaler\n",
    "        image = min_max_scaler(ruta, image)\n",
    "        ## binary image\n",
    "        binary_image = load_binary_images(mask_route)   \n",
    "        ## get features of the image            \n",
    "        features = annotations[annotations['folder'] == folder]\n",
    "        if features.shape[0] != 0:     \n",
    "            ## append rutas\n",
    "            geometric_attributes = get_geometric_atributes([binary_image])[0]\n",
    "            rutas_images.append(image_route)\n",
    "            rutas_masks.append(mask_route)\n",
    "            \n",
    "            ## append attributes\n",
    "            areas.append(geometric_attributes[0])\n",
    "            perimetros.append(geometric_attributes[1])\n",
    "            diametros.append(geometric_attributes[2])    \n",
    "            \n",
    "            ## evaluar si son nan e iomprimir solo si los  \n",
    "              \n",
    "            malignancy = features['malignancy'].values[0]\n",
    "            calsification = features['calcification'].values[0]\n",
    "            spiculation = features['spiculation'].values[0]\n",
    "            lobulation = features['lobulation'].values[0]\n",
    "            texture = features['texture'].values[0]\n",
    "            label = features['is_cancer'].values[0]\n",
    "            margin = features['margin'].values[0]\n",
    "            sublety = features['subtlety'].values[0]\n",
    "            \n",
    "            ## append featuresprint(features)\n",
    "            calsifications.append(calsification)\n",
    "            spiculations.append(spiculation)\n",
    "            lobulations.append(lobulation)\n",
    "            textures.append(texture)\n",
    "            labels.append(label)\n",
    "            margins.append(margin)\n",
    "            subletys.append(sublety)\n",
    "\n",
    "\n",
    "## build dataframe\n",
    "df = pd.DataFrame()\n",
    "df['ruta'] = rutas_images\n",
    "df['mask'] = rutas_masks\n",
    "df['area'] = areas\n",
    "df['perimetro'] = perimetros\n",
    "df['diametro'] = diametros\n",
    "df['calsification'] = calsifications\n",
    "df['spiculation'] = spiculations\n",
    "df['lobulation'] = lobulations\n",
    "df['texture'] = textures\n",
    "df['margin'] = margins\n",
    "df['sublety'] = subletys\n",
    "df['label'] = labels\n",
    "\n",
    "### eliminar filas con valores nan y decir cuantas se borraron\n",
    "#print('Filas antes de eliminar nan:', df.shape[0])\n",
    "#df = df.dropna()\n",
    "#print('Filas después de eliminar nan:', df.shape[0])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## shuffle data\n",
    "df_train_1, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "## validation split\n",
    "val_pctg = 0.8\n",
    "split_validation_index = int(df_train_1.shape[0]*val_pctg)\n",
    "df_train = df_train_1.iloc[:split_validation_index]\n",
    "df_validation = df_train_1.iloc[split_validation_index:]\n",
    "\n",
    "print('---- Distribución de entrenamiento, validación y test para benignos y malignos ----')\n",
    "print('Malignos: ')\n",
    "print('Positive train shape: ', df_train[df_train['label'] == 'True'].shape[0])\n",
    "print('Positive val shape: ', df_validation[df_validation['label'] == 'True'].shape[0])\n",
    "print('Positive test shape: ', df_test[df_test['label'] == 'True'].shape[0])\n",
    "\n",
    "print('Benignos: ')\n",
    "print('Negative train shape: ', df_train[df_train['label'] == 'False'].shape[0])\n",
    "print('Negative val shape: ', df_validation[df_validation['label'] == 'False'].shape[0])\n",
    "print('Negative test shape: ', df_test[df_test['label'] == 'False'].shape[0])\n",
    "\n",
    "## eliminar NaN\n",
    "df_train = df_train.dropna()\n",
    "df_test = df_test.dropna()\n",
    "df_validation = df_validation.dropna()\n",
    "\n",
    "\n",
    "## replace labels\n",
    "df_train.loc[:, 'label'] = df_train['label'].replace({'True': 1, 'False': 0})\n",
    "df_test.loc[:, 'label'] = df_test['label'].replace({'True': 1, 'False': 0})\n",
    "df_validation.loc[:, 'label'] = df_validation['label'].replace({'True': 1, 'False': 0})\n",
    "\n",
    "print('---- Dataset finales ----')\n",
    "print('Train shape: ', df_train.shape[0])\n",
    "print('Test shape: ', df_test.shape[0])\n",
    "print('Validation shape: ', df_validation.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot 5 first images with mas on the df train dataset\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(5):\n",
    "    image = load_images(df_train['ruta'].values[i])    \n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.imshow(image, cmap='gray')   \n",
    "    plt.title('Label: ' + str(df_train['label'].values[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create dataset function \n",
    "features_to_use = ['area','lobulation', 'texture', 'spiculation', 'margin']\n",
    "\n",
    "\n",
    "def create_train_dataset(batch,df):\n",
    "    images_routes = df['ruta'].to_numpy()\n",
    "    mask_routes = df['mask'].to_numpy()\n",
    "    labels = df['label'].to_numpy()\n",
    "    features = df[features_to_use].to_numpy()\n",
    "    \n",
    "    \n",
    "    ## Data augmentation    \n",
    "    def rotate90_image(image):\n",
    "        ## rotate 90 degrees\n",
    "        image = tf.image.rot90(image)\n",
    "        return image\n",
    "    \n",
    "    def rotate180_image(arg):\n",
    "        ## rotate 180 degrees\n",
    "        image = tf.image.rot90(arg, k=2)\n",
    "        return image\n",
    "    \n",
    "    def rotate270_image(arg):\n",
    "        ## rotate 270 degrees\n",
    "        image = tf.image.rot90(arg, k=3)\n",
    "        return image\n",
    "    \n",
    "    images = []\n",
    "    mask = []\n",
    "    new_labels = []\n",
    "    new_features = []\n",
    "    for image_route, mask_route, label, features in zip(images_routes,mask_routes, labels,features):\n",
    "        ## imagenes y mascaras originales\n",
    "        image_original = load_images(image_route)\n",
    "        mask_original = load_binary_images(mask_route)\n",
    "        \n",
    "        ## augmentaciones\n",
    "        # imagen original\n",
    "        #image_left_flip = f 'sublety'lip_left_image(image_original)\n",
    "        image_rotate90 = rotate90_image(image_original)\n",
    "        image_rotate180 = rotate180_image(image_original)\n",
    "        image_rotate270 = rotate270_image(image_original)\n",
    "        #image_up_flip = flip_up_image(image_original)\n",
    "        ## mascara original\n",
    "        #mask_left_flip = flip_left_image(mask_original)\n",
    "        mask_rotate90 = rotate90_image(mask_original)\n",
    "        mask_rotate180 = rotate180_image(mask_original)\n",
    "        mask_rotate270 = rotate270_image(mask_original)\n",
    "        #mask_up_flip = flip_up_image(mask_original)\n",
    "        \n",
    "        ## append image augmentation\n",
    "        images.append(image_original)        \n",
    "        images.append(image_rotate90)\n",
    "        images.append(image_rotate180)\n",
    "        images.append(image_rotate270)\n",
    "        \n",
    "        \n",
    "        ## append mask augmentation\n",
    "        mask.append(mask_original)        \n",
    "        mask.append(mask_rotate90)\n",
    "        mask.append(mask_rotate180)\n",
    "        mask.append(mask_rotate270)\n",
    "        \n",
    "        ## append labels        \n",
    "        new_labels.append(label)\n",
    "        new_labels.append(label)\n",
    "        new_labels.append(label)\n",
    "        new_labels.append(label)           \n",
    "        \n",
    "        ## append features  \n",
    "        new_features.append(features)\n",
    "        new_features.append(features)\n",
    "        new_features.append(features)\n",
    "        new_features.append(features)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    ## convert to tensor\n",
    "    images = tf.convert_to_tensor(images, dtype=tf.float32)\n",
    "    masks = tf.convert_to_tensor(mask, dtype=tf.float32)\n",
    "    labels = tf.convert_to_tensor(new_labels, dtype=tf.float32)\n",
    "    features = tf.convert_to_tensor(new_features, dtype=tf.float32)    \n",
    "    \n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, masks, features, labels))\n",
    "    \n",
    "    ## shuffle datad\n",
    "    dataset = dataset.shuffle(buffer_size=1000,seed=42)\n",
    "    \n",
    "    ## apply preprocess_image function\n",
    "    dataset = dataset.map(lambda image, mask, features, label: (image, mask, features, label))\n",
    "    \n",
    "    dataset = dataset.batch(batch)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "## create dataset function \n",
    "def create_test_dataset(batch,df):       \n",
    "    images_routes = df['ruta'].to_numpy()\n",
    "    mask_routes = df['mask'].to_numpy()\n",
    "    labels = df['label'].to_numpy()\n",
    "    features = df[features_to_use].to_numpy()\n",
    "    \n",
    "    \n",
    "    images = []\n",
    "    for image_route in images_routes:\n",
    "        image = load_images(image_route)\n",
    "        images.append(image)\n",
    "        \n",
    "    masks = []\n",
    "    for mask_route in mask_routes:\n",
    "        mask = load_binary_images(mask_route)\n",
    "        masks.append(mask)\n",
    "        \n",
    "    ## convert to tensor\n",
    "    images = tf.convert_to_tensor(images, dtype=tf.float32)\n",
    "    masks = tf.convert_to_tensor(mask, dtype=tf.float32)\n",
    "    labels = tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "    features = tf.convert_to_tensor(features, dtype=tf.float32)    \n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, masks, features, labels))\n",
    "    \n",
    "    ## apply preprocess_image function\n",
    "    dataset = dataset.map(lambda image, masks, features, label: (image, masks, features, label))\n",
    "      \n",
    "    dataset.batch(batch)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "## both-clases\n",
    "train_dataset = create_train_dataset(8, df_train)\n",
    "\n",
    "\n",
    "for image, mask, features, label in train_dataset:\n",
    "    print(image.shape)\n",
    "    print(mask.shape)\n",
    "    print(features.shape)\n",
    "    print(label.shape)    \n",
    "    break\n",
    "\n",
    "i = 0 \n",
    "for image, mask, features, label in train_dataset:\n",
    "    i += np.shape(image)[0]   \n",
    "\n",
    "print('Total de imagenes en el dataset de entrenamiento:', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask, features, label in train_dataset:\n",
    "    ## plot 8 batch images and their mask\n",
    "    plt.figure(figsize=(20,20))\n",
    "    for i in range(8):\n",
    "        plt.subplot(8,2,2*i+1)\n",
    "        plt.imshow(image[i], cmap='gray')       \n",
    "        plt.title('Image')\n",
    "        plt.subplot(8,2,2*i+2)\n",
    "        plt.imshow(mask[i], cmap='gray')\n",
    "        plt.title('Mask')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparámetros\n",
    "epochs = 2000\n",
    "learning_rate = 0.0001\n",
    "batch = 32\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dist-GVAE regressor from reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##___________________ REGRESSOR _________________________##\n",
    "latent_dim = 16\n",
    "nx, ny = 32, 32\n",
    "['area','lobulation', 'texture', 'spiculation', 'margin']\n",
    "\n",
    "## built regressor from latent embedding\n",
    "regressor_input = keras.Input(shape=(nx, ny,1))\n",
    "\n",
    "## Hidden layers\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same',name='layer_R1')(regressor_input)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same',name='layer_R2')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same',name='layer_R3')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same',name='layer_R4')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.Conv2D(4, (3, 3), activation='relu', padding='same',name='layer_R5')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same',name='layer_R6')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "flatten = layers.Flatten()(x)\n",
    "\n",
    "area_output = layers.Dense(1, name=\"area\",activation='relu')(flatten)\n",
    "\n",
    "lobulation_output = layers.Dense(1, name=\"lobulation\",activation='relu')(flatten)\n",
    "\n",
    "spiculation_output = layers.Dense(1, name=\"spiculation\",activation='relu')(flatten)\n",
    "\n",
    "margin_output = layers.Dense(1, name=\"margin\",activation='relu')(flatten)\n",
    "\n",
    "texture_output = layers.Dense(1, name=\"texture\",activation='relu')(flatten)\n",
    "\n",
    "## concatenar salidas en un solo tensor\n",
    "regressor_output = [area_output,lobulation_output, spiculation_output, margin_output, texture_output]\n",
    "\n",
    "regressor = keras.Model(inputs=regressor_input, outputs=regressor_output)\n",
    "\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###_____________________________ENCODER________________________##\n",
    "latent_dim = 16\n",
    "\n",
    "nx, ny = 32, 32\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(nx, ny, 1))\n",
    "\n",
    "## decoder\n",
    "nfilters = 16\n",
    "latent_dim = 16\n",
    "nx , ny = 32, 32\n",
    "\n",
    "\n",
    "encoder_input = keras.Input(shape=(nx,ny,1), name='original_img')\n",
    "\n",
    "c1 = layers.Conv2D(nfilters*1, kernel_size=(3,3),\n",
    "               kernel_initializer='he_normal', padding='same')(encoder_input)\n",
    "c1 = layers.BatchNormalization()(c1)\n",
    "c1 = layers.Activation('relu')(c1)\n",
    "p1 = layers.MaxPooling2D((2,2))(c1)\n",
    "p1 = layers.Dropout(0.1)(p1)\n",
    "\n",
    "c2 = layers.Conv2D(nfilters*2, kernel_size=(3,3),\n",
    "               kernel_initializer='he_normal', padding='same')(p1)\n",
    "c2 = layers.BatchNormalization()(c2)\n",
    "c2 = layers.Activation('relu')(c2)\n",
    "p2 = layers.MaxPooling2D((2,2))(c2)\n",
    "\n",
    "c3 = layers.Conv2D(nfilters*4, kernel_size=(3,3),\n",
    "               kernel_initializer='he_normal', padding='same')(p2)\n",
    "c3 = layers.BatchNormalization()(c3)\n",
    "c3 = layers.Activation('relu')(c3)\n",
    "p3 = layers.MaxPooling2D((2,2))(c3)\n",
    "p3 = layers.Dropout(0.1)(p3)\n",
    "\n",
    "c4 = layers.Conv2D(nfilters*8, kernel_size=(3,3),\n",
    "               kernel_initializer='he_normal', padding='same')(p3)\n",
    "c4 = layers.BatchNormalization()(c4)\n",
    "c4 = layers.Activation('relu')(c4)\n",
    "p4 = layers.MaxPooling2D((2,2))(c4)\n",
    "p4 = layers.Dropout(0.1)(p4)\n",
    "\n",
    "c5 = layers.Conv2D(nfilters*16, kernel_size=(3,3),\n",
    "               kernel_initializer='he_normal', padding='same')(p4)\n",
    "\n",
    "# Flatten and Embedding\n",
    "c5_flatten = layers.Flatten()(c5)\n",
    "x = layers.Dense(latent_dim, name='embedding')(c5_flatten)\n",
    "\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "encoder = keras.Model(inputs=encoder_input , outputs=[z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ------------------ decoder -------------------------\n",
    "## Entrada Z\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "## decoder layers from embedding\n",
    "d1_dec = layers.Dense(2*2*256, activation='relu')(latent_inputs)\n",
    "d1_dec = layers.Reshape((2, 2, 256))(d1_dec)\n",
    "\n",
    "u1_dec = layers.Conv2DTranspose(nfilters*16, (2,2), strides=(2,2), padding='same')(d1_dec)\n",
    "u1_dec = layers.Dropout(0.1)(u1_dec)\n",
    "c6_dec = layers.Conv2D(nfilters*16, kernel_size=(3,3),\n",
    "               kernel_initializer='he_normal', padding='same')(u1_dec)\n",
    "c6_dec = layers.BatchNormalization()(u1_dec)\n",
    "c6_dec = layers.Activation('relu')(u1_dec)\n",
    "\n",
    "u2_dec = layers.Conv2DTranspose(nfilters*8, (2,2), strides=(2,2), padding='same')(c6_dec)\n",
    "u2_dec = layers.Dropout(0.1)(u2_dec)\n",
    "c7_dec = layers.Conv2D(nfilters*8, kernel_size=(3,3),\n",
    "               kernel_initializer='he_normal', padding='same')(u2_dec)\n",
    "c7_dec = layers.BatchNormalization()(u2_dec)\n",
    "c7_dec = layers.Activation('relu')(u2_dec)\n",
    "\n",
    "u3_dec = layers.Conv2DTranspose(nfilters*4, (2,2), strides=(2,2), padding='same')(c7_dec)\n",
    "u3_dec = layers.Dropout(0.1)(u3_dec)\n",
    "c8_dec = layers.Conv2D(nfilters*4, kernel_size=(3,3),\n",
    "               kernel_initializer='he_normal', padding='same')(u3_dec)\n",
    "c8_dec = layers.BatchNormalization()(u3_dec)\n",
    "c8_dec = layers.Activation('relu')(u3_dec)\n",
    "\n",
    "u4_dec = layers.Conv2DTranspose(nfilters*2, (2,2), strides=(2,2), padding='same')(c8_dec)\n",
    "u4_dec = layers.Dropout(0.1)(u4_dec)\n",
    "c9_dec = layers.Conv2D(nfilters*2, kernel_size=(3,3),\n",
    "               kernel_initializer='he_normal', padding='same')(u4_dec)\n",
    "c9_dec = layers.BatchNormalization()(u4_dec)\n",
    "c9_dec = layers.Activation('relu')(u4_dec)\n",
    "\n",
    "segmentation_output = layers.Conv2D(1, (1,1), activation='sigmoid', name='segmentation')(c9_dec)\n",
    "\n",
    "## decoder model\n",
    "decoder = keras.Model(latent_inputs, segmentation_output, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, regressor, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.regressor = regressor\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.estimation_loss_tracker = keras.metrics.Mean(name=\"regression_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            self.estimation_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):       \n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            image = data[0]\n",
    "            mask = data[1]\n",
    "            features =  data[2]\n",
    "            z_mean, z_log_var, z = self.encoder(image)\n",
    "            reconstruction = self.decoder(z)\n",
    "            #reconstruction /= tf.reduce_max(reconstruction)\n",
    "            estimations = self.regressor(reconstruction)\n",
    "            \n",
    "            reconstruction_loss = tf.math.abs(tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                   keras.losses.binary_crossentropy(mask, refrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStoppingconstruction), axis=(1, 2)\n",
    "                )\n",
    "            ))        \n",
    "            \n",
    "            estimation_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.mean_squared_error(features, estimations), axis=(1)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))            \n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))  \n",
    "                                \n",
    "            total_loss = reconstruction_loss + kl_loss + estimation_loss\n",
    "            \n",
    "            \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)        \n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        self.estimation_loss_tracker.update_state(estimation_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "            \"estimation_loss\": self.estimation_loss_tracker.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, decoder,regressor)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "#nll = lambda x , rv_x: -rv_x.log_prob(x)\n",
    "vae.compile(optimizer=opt)\n",
    "\n",
    "\n",
    "vae.fit(train_dataset, epochs=epochs, \n",
    "                batch_size=batch,\n",
    "                         callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=30)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Guardar modelohttps://www.tensorflow.org/guide/saved_model?hl=es-419\n",
    "vae.encoder.save('DistVAE_Models/DistGVAE_convReg_Segmentation_16_encoder.h5')\n",
    "vae.decoder.save('DistVAE_Models/DistGVAE_convReg_Segmentation_16_decoder.h5')\n",
    "vae.regressor.save('DistVAE_Models/DistGVAE_convReg_Segmentation_16_regressor.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
